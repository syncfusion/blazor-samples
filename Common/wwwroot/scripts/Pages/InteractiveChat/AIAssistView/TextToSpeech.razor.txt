@page "/ai-assistview/ai-texttospeech"

@using Syncfusion.Blazor.InteractiveChat
@using AIAssistView_AzureAI.Components.Services
@using Syncfusion.Blazor.Navigations
@inject AzureOpenAIService OpenAIService
@inject IJSRuntime JSRuntime
@implements IDisposable

<ActionDescription>
<p>This sample demonstrates the integration of <code>Text-to-Speech</code> with the <code>AI AssistView</code> component, enabling users to convert AI-generated responses into spoken audio via the browser’s Web Speech API for voice-based interaction.</p>
    
    <p><b>Key Features:</b></p>
    <ul>
        <li>The <code>responseToolbarSettings</code> includes a custom <code>Read Aloud</code> button that extracts plain text from the AI response and uses the browser's <code>SpeechSynthesis</code> API to vocalize it.</li>
        <li>The <code>SpeechSynthesisUtterance</code> interface is used to manage speech playback, including toggling between play and stop states.</li>
        <li>The <code>toolbarSettings</code> adds a right-aligned <code>Refresh</code> button to clear previous prompts.</li>
        <li>Responses are streamed dynamically using the <code>addPromptResponse</code> method, and the <code>scrollToBottom</code> method ensures the latest response is always visible.</li>
        <li>Markdown content is rendered using the <code>Marked</code> plugin for rich formatting in AI responses.</li>
    </ul>
</ActionDescription>

<div class="control-section">
<div class="integration-texttospeech-section">
    <SfAIAssistView @ref="assistView" PromptRequested="@PromptRequest" Prompts="@prompts">
        <AssistViewToolbar ItemClicked="ToolbarItemClicked">
            <AssistViewToolbarItem Type="ItemType.Spacer"></AssistViewToolbarItem>
            <AssistViewToolbarItem IconCss="e-icons e-refresh"></AssistViewToolbarItem>
        </AssistViewToolbar>
        <ResponseToolbar ItemClicked="ResponseToolbarItemClicked">
            <ResponseToolbarItem IconCss="e-icons e-assist-copy" Tooltip="Copy"></ResponseToolbarItem>
            <ResponseToolbarItem IconCss="@audioIconCss" Tooltip="@audioTooltip"></ResponseToolbarItem>
            <ResponseToolbarItem IconCss="e-icons e-assist-like" Tooltip="Like"></ResponseToolbarItem>
            <ResponseToolbarItem IconCss="e-icons e-assist-dislike" Tooltip="Need Improvement"></ResponseToolbarItem>
        </ResponseToolbar>
    </SfAIAssistView>
</div>
</div>
@code {
    private SfAIAssistView assistView;
    private string finalResponse { get; set; }
    private string audioIconCss = "e-icons e-audio";
    private string audioTooltip = "Read Aloud";
    private bool IsSpeaking = false;
    private List<AssistViewPrompt> prompts = new List<AssistViewPrompt>()
  {
      new AssistViewPrompt() { Prompt = "What is AI?", Response = "<div>AI stands for Artificial Intelligence, enabling machines to mimic human intelligence for tasks such as learning, problem-solving, and decision-making.</div>" }
  };
    // If component class name isn’t Home (file is not Home.razor), update DotNetObjectReference to match the actual component type.
    private DotNetObjectReference<TextToSpeech>? dotNetRef;

    protected override void OnInitialized()
    {
        dotNetRef = DotNetObjectReference.Create(this);
    }

    private async Task PromptRequest(AssistViewPromptRequestedEventArgs args)
    {
        var lastIdx = assistView.Prompts.Count - 1;
        assistView.Prompts[lastIdx].Response = string.Empty;
        finalResponse = string.Empty;
        try
        {
            await foreach (var chunk in OpenAIService.GetChatResponseStreamAsync(args.Prompt))
            {
                await UpdateResponse(args, chunk);
            }

            args.Response = finalResponse;
        }
        catch (Exception ex)
        {
            args.Response = "⚠️ Something went wrong while connecting to the OpenAI service. Please check your API key or try again later.";
        }
    }

    private async Task UpdateResponse(AssistViewPromptRequestedEventArgs args, string response)
    {
        var lastIdx = assistView.Prompts.Count - 1;
        await Task.Delay(30); // Small delay for UI updates
        assistView.Prompts[lastIdx].Response += response.Replace("\n", "<br>");
        finalResponse = assistView.Prompts[lastIdx].Response;
        StateHasChanged();
    }

    private void ToolbarItemClicked(AssistViewToolbarItemClickedEventArgs args)
    {
        if (args.Item.IconCss == "e-icons e-refresh")
        {
            assistView.Prompts.Clear();
        }
    }

    // Handles toolbar item clicks to toggle text-to-speech functionality for AI responses
    private async void ResponseToolbarItemClicked(AssistViewToolbarItemClickedEventArgs args)
    {
        var prompts = assistView.Prompts;
        if (prompts.Count > args.DataIndex && prompts[args.DataIndex].Response != null)
        {
            string responseHtml = prompts[args.DataIndex].Response;
            string text = await JSRuntime.InvokeAsync<string>("extractTextFromHtml", responseHtml);

            if (args.Item.IconCss == "e-icons e-audio" || args.Item.IconCss == "e-icons e-assist-stop")
            {
                if (IsSpeaking)
                {
                    await JSRuntime.InvokeVoidAsync("cancel");
                    IsSpeaking = false;
                    audioIconCss = "e-icons e-audio";
                    audioTooltip = "Read Aloud";
                }
                else if (!string.IsNullOrEmpty(text))
                {
                    IsSpeaking = await JSRuntime.InvokeAsync<bool>("speak", text, dotNetRef);
                    if (IsSpeaking)
                    {
                        audioIconCss = "e-icons e-assist-stop";
                        audioTooltip = "Stop";
                    }
                    else
                    {
                        await JSRuntime.InvokeVoidAsync("console.warn", "Failed to start speech synthesis.");
                    }
                }
                await InvokeAsync(StateHasChanged);
            }
        }
    }

    [JSInvokable]
    public void OnSpeechEnd()
    {
        IsSpeaking = false;
        audioIconCss = "e-icons e-audio";
        audioTooltip = "Read Aloud";
        StateHasChanged();
    }

    public void Dispose()
    {
        dotNetRef?.Dispose();
        dotNetRef = null;
    }
}
<style>
    .integration-texttospeech-section {
        height: 550px;
        width: 550px;
        margin: 0 auto;
    }
    @@media only screen and (max-width: 750px) {
        .integration-texttospeech-section
    {
        width: 100%;
    }

    }
</style>