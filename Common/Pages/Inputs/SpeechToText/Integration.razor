@page "/speech-to-text/integration"

@using Syncfusion.Blazor.InteractiveChat
@using Syncfusion.Blazor.Buttons
@using Syncfusion.Blazor.Navigations
@using Syncfusion.Blazor.Inputs
@using Syncfusion.Blazor.Notifications
@using Microsoft.AspNetCore.Components

@*Hidden:Lines*@
@inherits SampleBaseComponent
@inject NavigationManager NavigationManager
@inject IJSRuntime JSRuntime


@*End:Hidden*@

<SampleDescription>
    <p>
        This sample demonstrates the integration of SpeechToText with the AI AssistView component. It allows users to convert spoken words into text in real time and use the transcribed content as input for AI-based interactions.
    </p>
</SampleDescription>
<ActionDescription>
    <p>
        In this example, the SpeechToText component captures and transcribes spoken input into text, which is displayed in an editable area. Users can modify the transcribed text or send it directly to the AI AssistView for processing.
    </p>
    <p>
        The AI AssistView responds based on the provided input. A toolbar option is available to clear the conversation history, and a toast notification alerts users to any speech recognition errors.
    </p>
</ActionDescription>

<div class="control-section integration-control-section">
    <div class="integration-speechToText-section">
        <SfToast @ref="@ToastObj" Target="@ToastTarget">
            <ToastPosition X="Right"></ToastPosition>
        </SfToast>
        <SfAIAssistView @ref="SfAIAssistView" PromptRequested="@PromptRequest">
            <AssistViews>
                <AssistView>
                    <FooterTemplate>
                        <div class="e-footer-wrapper">
                            <div id="assistview-footer" class="content-editor" contenteditable="true" placeholder="Click to speak or start typing..." @oninput="@UpdateContent" @onkeydown="@OnKeyDown" @ref="@EditableDiv">@AssistViewFooterValue</div>
                            <div class="option-container">
                                <SfSpeechToText ID="speechToText" TranscriptChanging="@OnTranscriptChange" SpeechRecognitionStopped="@HandleStopRecognition"
                                SpeechRecognitionError="OnError" CssClass="@($"e-flat {SpeechToTextCssClass}")" Disabled="@DisabledState"></SfSpeechToText>
                                <SfButton ID="assistview-sendButton" IconCss="e-assist-send e-icons" CssClass="@ButtonCssClass" @onclick="SendButtonClicked"></SfButton>
                            </div>
                        </div>
                    </FooterTemplate>
                    <BannerTemplate>
                        <div class="banner-info">
                            <div class="e-icons e-listen-icon"></div>
                            <h3>Speech To Text</h3>
                            <i>Click the below mic-button to convert your voice to text.</i>
                        </div>
                    </BannerTemplate>
                </AssistView>
            </AssistViews>
            <AssistViewToolbar ItemClicked="ToolbarItemClicked">
                <AssistViewToolbarItem Type="ItemType.Spacer"></AssistViewToolbarItem>
                <AssistViewToolbarItem IconCss="e-icons e-refresh"></AssistViewToolbarItem>
            </AssistViewToolbar>
        </SfAIAssistView>
    </div>
</div>
@code {
    private SfAIAssistView SfAIAssistView = new SfAIAssistView();
    private SfToast ToastObj = new SfToast();
    private string AssistViewFooterValue = String.Empty;
    private ElementReference EditableDiv;
    private string FooterContent = String.Empty;
    private string SpeechToTextCssClass = "visible";
    private string ButtonCssClass = String.Empty;
    private bool DisabledState = false;
    private string ToastTarget = ".integration-control-section";

    private async Task OnError(SpeechRecognitionErrorEventArgs args)
    {
        int timeout = args.Error == "unsupported-browser" ? 0 : 5000;
        ToastModel toastModel = new ToastModel
        {
            Content = args.ErrorMessage,
            Timeout = timeout,
            CssClass = "e-toast-danger",
            Target = ToastTarget
        };
        if (args.Error == "unsupported-browser")
        {
            DisabledState = true;
        }
        await ToastObj.ShowAsync(toastModel);
    }
    private async void OnTranscriptChange(TranscriptChangeEventArgs args)
    {
        AssistViewFooterValue = args.Transcript;
        await JSRuntime.InvokeVoidAsync("updateContentEditableDiv", EditableDiv, AssistViewFooterValue);
        await InvokeAsync(StateHasChanged);
    }
    private async Task UpdateContent()
    {
        FooterContent = await JSRuntime.InvokeAsync<String>("isFooterContainsValue", EditableDiv);
        ToggleVisibility();
    }

    private async Task HandleStopRecognition()
    {
        FooterContent = AssistViewFooterValue;
        ToggleVisibility();
        await InvokeAsync(StateHasChanged);
    }

    private void ToggleVisibility()
    {
        ButtonCssClass = string.IsNullOrWhiteSpace(FooterContent) ? "" : "visible";
        SpeechToTextCssClass = string.IsNullOrWhiteSpace(FooterContent) ? "visible" : "";
    }

    private async Task PromptRequest(AssistViewPromptRequestedEventArgs args)
    {
        AssistViewFooterValue = String.Empty;
        await Task.Delay(50);
        await JSRuntime.InvokeVoidAsync("emptyFooterValue", EditableDiv);
        await UpdateContent();
        await Task.Delay(2000);
        var defaultResponse = "For real-time prompt processing, connect the AIAssistView component to your preferred AI service.";
        args.Response = defaultResponse;
    }

    private async Task SendButtonClicked()
    {
        await SfAIAssistView.ExecutePromptAsync(FooterContent);
    }

    private void ToolbarItemClicked(AssistViewToolbarItemClickedEventArgs args)
    {
        if (args.Item.IconCss == "e-icons e-refresh")
        {
            SfAIAssistView.Prompts.Clear();
        }
    }

    private async Task OnKeyDown(KeyboardEventArgs e)
    {
        if (e.Key == "Enter" && !e.ShiftKey)
        {
            await SendButtonClicked();
        }

    }
}
<style>

    .integration-speechToText-section {
        height: 550px;
        width: 550px;
        margin: 0 auto;
    }

    .integration-speechToText-section .banner-info .e-listen-icon:before {
        font-size: 35px;
    }

    .integration-speechToText-section .banner-info {
        display: flex;
        flex-direction: column;
        justify-content: center;
        height: 330px;
        text-align: center;
    }

    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton {
        width: 40px;
        height: 40px;
        font-size: 20px;
        border: none;
        background: none;
        cursor: pointer;
    }

    .integration-speechToText-section .e-footer-wrapper #speechToText.visible,
    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton.visible {
        display: inline-block;
    }

    .integration-speechToText-section .e-footer-wrapper #speechToText,
    .integration-speechToText-section .e-footer-wrapper #assistview-sendButton {
        display: none;
    }

    @@media only screen and (max-width: 750px) {
        .integration-speechToText-section {
            width: 100%;
        }
    }

    .integration-speechToText-section .e-footer-wrapper {
        display: flex;
        border: 1px solid #c1c1c1;
        padding: 5px 5px 5px 10px;
        margin: 5px 5px 0 5px;
        border-radius: 30px;
    }

    .integration-speechToText-section .e-footer-wrapper .content-editor {
        width: 100%;
        overflow-y: auto;
        font-size: 14px;
        min-height: 25px;
        max-height: 200px;
        padding: 10px;
        scrollbar-color: #c1c1c1 transparent;
    }

    .integration-speechToText-section .e-footer-wrapper .content-editor[contentEditable=true]:empty:before {
        content: attr(placeholder)
    }

    .integration-speechToText-section .option-container {
        align-self: flex-end;
    }
</style>
